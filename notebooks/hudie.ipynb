{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2f5e59-fd55-4cf0-b74f-6e2491bc2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat, col, when, lit, unix_timestamp\n",
    "\n",
    "# Set up Spark session\n",
    "package = \"org.apache.hudi:hudi-spark3.4-bundle_2.12:0.15.0\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hudi Basics\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\") \\\n",
    "    .config(\"spark.jars.packages\", package) \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\")\\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\\\n",
    "    .config(\"spark.kryo.registrator\", \"org.apache.spark.HoodieSparkKryoRegistrar\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b33740-8888-4fab-b1f5-71a0b263f759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3865f7754596:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Hudi Basics</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6b6a101610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31a9fa67-9f22-4dd2-99b0-c8aa8bb07d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hudi write options\n",
    "hudi_options = {\n",
    "    'hoodie.table.name': 'test_cdc_table1',\n",
    "    'hoodie.datasource.write.recordkey.field': 'id',\n",
    "    'hoodie.datasource.write.precombine.field': 'precombine_key',\n",
    "    'hoodie.datasource.write.operation': 'upsert',\n",
    "    'hoodie.upsert.shuffle.parallelism': 2,\n",
    "    'hoodie.insert.shuffle.parallelism': 2\n",
    "}\n",
    "\n",
    "# Function to create precombine key\n",
    "def create_precombine_key(df):\n",
    "    df = df.withColumn(\"op_value\", \n",
    "                       when(col(\"operation_type\") == \"U\", 3)\n",
    "                       .when(col(\"operation_type\") == \"I\", 2)\n",
    "                       .when(col(\"operation_type\") == \"D\", 1)\n",
    "                       .otherwise(0))\n",
    "    \n",
    "    return df.withColumn(\"precombine_key\", \n",
    "                         unix_timestamp(col(\"operation_datetime\")).cast(\"long\") + col(\"op_value\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8037c18-95ea-42bb-a5b5-86c014b5c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle deletes\n",
    "def handle_deletes(df):\n",
    "    deletes = df.filter(col(\"operation_type\") == \"D\")\n",
    "    non_deletes = df.filter(col(\"operation_type\") != \"D\")\n",
    "    \n",
    "    deletes = deletes.withColumn(\"_hoodie_is_deleted\", lit(True))\n",
    "    non_deletes = non_deletes.withColumn(\"_hoodie_is_deleted\", lit(False))\n",
    "    \n",
    "    return non_deletes.union(deletes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb459ac8-daa1-4386-b6d8-33625c49e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "+---+-------------------+--------------+--------------------+\n",
      "| id| operation_datetime|operation_type|                  _4|\n",
      "+---+-------------------+--------------+--------------------+\n",
      "|  1|2023-08-10 10:00:00|             I|      Initial insert|\n",
      "|  1|2023-08-10 11:00:00|             U| Update 1 hour later|\n",
      "|  1|2023-08-10 12:00:00|             D|Delete 2 hours later|\n",
      "|  1|2023-08-10 13:00:00|             I|Re-insert 3 hours...|\n",
      "|  2|2023-08-10 14:00:00|             I|      Initial insert|\n",
      "|  2|2023-08-10 14:00:00|             U|Update at the sam...|\n",
      "|  3|2023-08-10 15:00:00|             I|      Initial insert|\n",
      "|  3|2023-08-10 16:00:00|             D|              Delete|\n",
      "|  3|2023-08-10 17:00:00|             I|           Re-insert|\n",
      "|  4|2023-08-10 18:00:00|             I|      Initial insert|\n",
      "|  4|2023-08-10 19:00:00|             U|            Update 1|\n",
      "|  4|2023-08-10 20:00:00|             U|            Update 2|\n",
      "|  5|2023-08-10 21:00:00|             I|      Initial insert|\n",
      "|  5|2023-08-10 22:00:00|             D|              Delete|\n",
      "|  5|2023-08-10 23:00:00|             I|          New insert|\n",
      "+---+-------------------+--------------+--------------------+\n",
      "\n",
      "DataFrame with precombine key:\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+\n",
      "| id| operation_datetime|operation_type|                  _4|op_value|precombine_key|\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+\n",
      "|  1|2023-08-10 10:00:00|             I|      Initial insert|       2|    1691661602|\n",
      "|  1|2023-08-10 11:00:00|             U| Update 1 hour later|       3|    1691665203|\n",
      "|  1|2023-08-10 12:00:00|             D|Delete 2 hours later|       1|    1691668801|\n",
      "|  1|2023-08-10 13:00:00|             I|Re-insert 3 hours...|       2|    1691672402|\n",
      "|  2|2023-08-10 14:00:00|             I|      Initial insert|       2|    1691676002|\n",
      "|  2|2023-08-10 14:00:00|             U|Update at the sam...|       3|    1691676003|\n",
      "|  3|2023-08-10 15:00:00|             I|      Initial insert|       2|    1691679602|\n",
      "|  3|2023-08-10 16:00:00|             D|              Delete|       1|    1691683201|\n",
      "|  3|2023-08-10 17:00:00|             I|           Re-insert|       2|    1691686802|\n",
      "|  4|2023-08-10 18:00:00|             I|      Initial insert|       2|    1691690402|\n",
      "|  4|2023-08-10 19:00:00|             U|            Update 1|       3|    1691694003|\n",
      "|  4|2023-08-10 20:00:00|             U|            Update 2|       3|    1691697603|\n",
      "|  5|2023-08-10 21:00:00|             I|      Initial insert|       2|    1691701202|\n",
      "|  5|2023-08-10 22:00:00|             D|              Delete|       1|    1691704801|\n",
      "|  5|2023-08-10 23:00:00|             I|          New insert|       2|    1691708402|\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+\n",
      "\n",
      "Processed DataFrame:\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+------------------+\n",
      "| id| operation_datetime|operation_type|                  _4|op_value|precombine_key|_hoodie_is_deleted|\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+------------------+\n",
      "|  1|2023-08-10 10:00:00|             I|      Initial insert|       2|    1691661602|             false|\n",
      "|  1|2023-08-10 11:00:00|             U| Update 1 hour later|       3|    1691665203|             false|\n",
      "|  1|2023-08-10 13:00:00|             I|Re-insert 3 hours...|       2|    1691672402|             false|\n",
      "|  2|2023-08-10 14:00:00|             I|      Initial insert|       2|    1691676002|             false|\n",
      "|  2|2023-08-10 14:00:00|             U|Update at the sam...|       3|    1691676003|             false|\n",
      "|  3|2023-08-10 15:00:00|             I|      Initial insert|       2|    1691679602|             false|\n",
      "|  3|2023-08-10 17:00:00|             I|           Re-insert|       2|    1691686802|             false|\n",
      "|  4|2023-08-10 18:00:00|             I|      Initial insert|       2|    1691690402|             false|\n",
      "|  4|2023-08-10 19:00:00|             U|            Update 1|       3|    1691694003|             false|\n",
      "|  4|2023-08-10 20:00:00|             U|            Update 2|       3|    1691697603|             false|\n",
      "|  5|2023-08-10 21:00:00|             I|      Initial insert|       2|    1691701202|             false|\n",
      "|  5|2023-08-10 23:00:00|             I|          New insert|       2|    1691708402|             false|\n",
      "|  1|2023-08-10 12:00:00|             D|Delete 2 hours later|       1|    1691668801|              true|\n",
      "|  3|2023-08-10 16:00:00|             D|              Delete|       1|    1691683201|              true|\n",
      "|  5|2023-08-10 22:00:00|             D|              Delete|       1|    1691704801|              true|\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "    # Scenario 1: Multiple operations on the same key\n",
    "    (\"1\", \"2023-08-10 10:00:00\", \"I\", \"Initial insert\"),\n",
    "    (\"1\", \"2023-08-10 11:00:00\", \"U\", \"Update 1 hour later\"),\n",
    "    (\"1\", \"2023-08-10 12:00:00\", \"D\", \"Delete 2 hours later\"),\n",
    "    (\"1\", \"2023-08-10 13:00:00\", \"I\", \"Re-insert 3 hours later\"),\n",
    "\n",
    "    # Scenario 2: Operations with the same timestamp\n",
    "    (\"2\", \"2023-08-10 14:00:00\", \"I\", \"Initial insert\"),\n",
    "    (\"2\", \"2023-08-10 14:00:00\", \"U\", \"Update at the same time\"),\n",
    "\n",
    "    # Scenario 3: Delete followed by insert\n",
    "    (\"3\", \"2023-08-10 15:00:00\", \"I\", \"Initial insert\"),\n",
    "    (\"3\", \"2023-08-10 16:00:00\", \"D\", \"Delete\"),\n",
    "    (\"3\", \"2023-08-10 17:00:00\", \"I\", \"Re-insert\"),\n",
    "\n",
    "    # Scenario 4: Multiple updates\n",
    "    (\"4\", \"2023-08-10 18:00:00\", \"I\", \"Initial insert\"),\n",
    "    (\"4\", \"2023-08-10 19:00:00\", \"U\", \"Update 1\"),\n",
    "    (\"4\", \"2023-08-10 20:00:00\", \"U\", \"Update 2\"),\n",
    "\n",
    "    # Scenario 5: Insert after delete\n",
    "    (\"5\", \"2023-08-10 21:00:00\", \"I\", \"Initial insert\"),\n",
    "    (\"5\", \"2023-08-10 22:00:00\", \"D\", \"Delete\"),\n",
    "    (\"5\", \"2023-08-10 23:00:00\", \"I\", \"New insert\")\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, [\"id\", \"operation_datetime\", \"operation_type\"])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "df.show()\n",
    "\n",
    "# Create the precombine key\n",
    "df_with_precombine = create_precombine_key(df)\n",
    "print(\"DataFrame with precombine key:\")\n",
    "df_with_precombine.show()\n",
    "\n",
    "# Process deletes\n",
    "df_processed = handle_deletes(df_with_precombine)\n",
    "\n",
    "print(\"Processed DataFrame:\")\n",
    "df_processed.show()\n",
    "\n",
    "# Write to Hudi\n",
    "df_processed.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").save(\"/home/jovyan/test_cdc_table1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f78c130-f246-4343-9a5e-11c7f507a07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from Hudi table:\n",
      "+-------------------+---------------------+------------------+----------------------+-------------------------------------------------------------------------+---+-------------------+--------------+-----------------------+--------+--------------+------------------+\n",
      "|_hoodie_commit_time|_hoodie_commit_seqno |_hoodie_record_key|_hoodie_partition_path|_hoodie_file_name                                                        |id |operation_datetime |operation_type|_4                     |op_value|precombine_key|_hoodie_is_deleted|\n",
      "+-------------------+---------------------+------------------+----------------------+-------------------------------------------------------------------------+---+-------------------+--------------+-----------------------+--------+--------------+------------------+\n",
      "|20240810122847683  |20240810122847683_0_0|1                 |                      |bf092cf4-ade6-4178-9dcd-b139dce3d42c-0_0-33-119_20240810122847683.parquet|1  |2023-08-10 13:00:00|I             |Re-insert 3 hours later|2       |16916724002   |false             |\n",
      "|20240810122847683  |20240810122847683_0_1|3                 |                      |bf092cf4-ade6-4178-9dcd-b139dce3d42c-0_0-33-119_20240810122847683.parquet|3  |2023-08-10 17:00:00|I             |Re-insert              |2       |16916868002   |false             |\n",
      "|20240810122847683  |20240810122847683_0_2|5                 |                      |bf092cf4-ade6-4178-9dcd-b139dce3d42c-0_0-33-119_20240810122847683.parquet|5  |2023-08-10 23:00:00|I             |New insert             |2       |16917084002   |false             |\n",
      "|20240810122847683  |20240810122847683_0_3|2                 |                      |bf092cf4-ade6-4178-9dcd-b139dce3d42c-0_0-33-119_20240810122847683.parquet|2  |2023-08-10 14:00:00|U             |Update at the same time|3       |16916760003   |false             |\n",
      "|20240810122847683  |20240810122847683_0_4|4                 |                      |bf092cf4-ade6-4178-9dcd-b139dce3d42c-0_0-33-119_20240810122847683.parquet|4  |2023-08-10 20:00:00|U             |Update 2               |3       |16916976003   |false             |\n",
      "+-------------------+---------------------+------------------+----------------------+-------------------------------------------------------------------------+---+-------------------+--------------+-----------------------+--------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading from Hudi table\n",
    "hudi_df = spark.read.format(\"hudi\").load(\"/home/jovyan/test_cdc_table\")\n",
    "print(\"Data read from Hudi table:\")\n",
    "hudi_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99327da8-dc7f-4612-bacc-4d49fe123873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------------+--------------------+--------+--------------+------------------+\n",
      "| id| operation_datetime|operation_type|                  _4|op_value|precombine_key|_hoodie_is_deleted|\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+------------------+\n",
      "|  1|2023-08-10 10:00:00|             I|      Initial insert|       2|   16916616002|             false|\n",
      "|  1|2023-08-10 11:00:00|             U| Update 1 hour later|       3|   16916652003|             false|\n",
      "|  1|2023-08-10 12:00:00|             D|Delete 2 hours later|       1|   16916688001|              true|\n",
      "|  1|2023-08-10 13:00:00|             I|Re-insert 3 hours...|       2|   16916724002|             false|\n",
      "|  2|2023-08-10 14:00:00|             I|      Initial insert|       2|   16916760002|             false|\n",
      "|  2|2023-08-10 14:00:00|             U|Update at the sam...|       3|   16916760003|             false|\n",
      "|  3|2023-08-10 15:00:00|             I|      Initial insert|       2|   16916796002|             false|\n",
      "|  3|2023-08-10 16:00:00|             D|              Delete|       1|   16916832001|              true|\n",
      "|  3|2023-08-10 17:00:00|             I|           Re-insert|       2|   16916868002|             false|\n",
      "|  4|2023-08-10 18:00:00|             I|      Initial insert|       2|   16916904002|             false|\n",
      "|  4|2023-08-10 19:00:00|             U|            Update 1|       3|   16916940003|             false|\n",
      "|  4|2023-08-10 20:00:00|             U|            Update 2|       3|   16916976003|             false|\n",
      "|  5|2023-08-10 21:00:00|             I|      Initial insert|       2|   16917012002|             false|\n",
      "|  5|2023-08-10 22:00:00|             D|              Delete|       1|   16917048001|              true|\n",
      "|  5|2023-08-10 23:00:00|             I|          New insert|       2|   16917084002|             false|\n",
      "+---+-------------------+--------------+--------------------+--------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_processed.orderBy([col(\"id\"), col(\"precombine_key\")]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630390f-b90b-4d52-a032-109eeb59d068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
